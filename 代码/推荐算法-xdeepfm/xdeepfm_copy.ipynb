{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e99fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a5d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.out_layer = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        output = self.out_layer(inputs)\n",
    "        return output\n",
    "\n",
    "class Dense_layer(Layer):\n",
    "    def __init__(self, hidden_units, out_dim=1, activation='relu', dropout=0.0):\n",
    "        super(Dense_layer, self).__init__()\n",
    "        self.hidden_layers = [Dense(i, activation=activation) for i in hidden_units]\n",
    "        self.out_layer = Dense(out_dim, activation=None)\n",
    "        self.dropout = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # inputs: [None, n*k]\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.out_layer(x)\n",
    "        return output\n",
    "\n",
    "class CIN(Layer):\n",
    "    def __init__(self, cin_size):\n",
    "        super(CIN, self).__init__()\n",
    "        self.cin_size = cin_size  # 每层的矩阵个数\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape: [[None, n, k]None, n, k]\n",
    "        self.field_num = [input_shape[1]] + self.cin_size # 每层的矩阵个数(包括第0层)\n",
    "\n",
    "        self.cin_W = [self.add_weight(\n",
    "                         name='w'+str(i),\n",
    "                         shape=(1, self.field_num[0]*self.field_num[i], self.field_num[i+1]),\n",
    "                         initializer=tf.initializers.glorot_uniform(),\n",
    "                         regularizer=tf.keras.regularizers.l1_l2(1e-5),\n",
    "                         trainable=True)\n",
    "                      for i in range(len(self.field_num)-1)]\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # inputs: [None, n, k], 只有SparseFeature \n",
    "        k = inputs.shape[-1]\n",
    "        res_list = [inputs]\n",
    "        X0 = tf.split(inputs, k, axis=-1)           # 最后维切成k份，list: k * [None, field_num[0], 1]\n",
    "        for i, size in enumerate(self.field_num[1:]):\n",
    "            Xi = tf.split(res_list[-1], k, axis=-1) # list: k * [None, field_num[i], 1]\n",
    "            #A batch matrix multiplication with batch shape [2]:\n",
    "            #高纬下也只是取倒数第二维度\n",
    "            x = tf.matmul(X0, Xi, transpose_b=True) # list: k * [None, field_num[0], field_num[i]]\n",
    "            x = tf.reshape(x, shape=[k, -1, self.field_num[0]*self.field_num[i]])\n",
    "                                                    # [k, None, field_num[0]*field_num[i]]\n",
    "            x = tf.transpose(x, [1, 0, 2])          # [None, k, field_num[0]*field_num[i]]\n",
    "            x = tf.nn.conv1d(input=x, filters=self.cin_W[i], stride=1, padding='VALID')\n",
    "                                                    # (None, k, field_num[i+1])\n",
    "            x = tf.transpose(x, [0, 2, 1])          # (None, field_num[i+1], k)\n",
    "            res_list.append(x)\n",
    "\n",
    "        res_list = res_list[1:]   # 去掉X0\n",
    "        res = tf.concat(res_list, axis=1)  # (None, field_num[1]+...+field_num[n], k)\n",
    "        output = tf.reduce_sum(res, axis=-1)  # (None, field_num[1]+...+field_num[n])\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3789267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "\n",
    "class xDeepFM(Model):\n",
    "    def __init__(self, feature_columns, cin_size, hidden_units, out_dim=1, activation='relu', dropout=0.0):\n",
    "        super(xDeepFM, self).__init__()\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns\n",
    "        self.embed_layers = [Embedding(feat['feat_onehot_dim'], feat['embed_dim'])\n",
    "                                    for feat in self.sparse_feature_columns]\n",
    "        self.linear = Linear()\n",
    "        self.dense_layer = Dense_layer(hidden_units, out_dim, activation, dropout)\n",
    "        self.cin_layer = CIN(cin_size)\n",
    "        self.out_layer = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        dense_inputs, sparse_inputs = inputs[:, :13], inputs[:, 13:]\n",
    "\n",
    "        # linear\n",
    "        linear_out = self.linear(inputs)\n",
    "\n",
    "        emb = [self.embed_layers[i](sparse_inputs[:, i]) for i in range(sparse_inputs.shape[1])] # [n, None, k]\n",
    "        emb = tf.transpose(tf.convert_to_tensor(emb), [1, 0, 2]) # [None, n, k]\n",
    "\n",
    "        # CIN\n",
    "        cin_out = self.cin_layer(emb)\n",
    "\n",
    "        # dense\n",
    "        emb = tf.reshape(emb, shape=(-1, emb.shape[1]*emb.shape[2]))\n",
    "        emb = tf.concat([dense_inputs, emb], axis=1)\n",
    "        dense_out = self.dense_layer(emb)\n",
    "\n",
    "        output = self.out_layer(linear_out + cin_out + dense_out)\n",
    "        return tf.nn.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72b69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Time   : 2021/1/3 11:08\n",
    "# Author : junchaoli\n",
    "# File   : utils.py\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sparseFeature(feat, feat_onehot_dim, embed_dim):\n",
    "    return {'feat': feat, 'feat_onehot_dim': feat_onehot_dim, 'embed_dim': embed_dim}\n",
    "\n",
    "def denseFeature(feat):\n",
    "    return {'feat': feat}\n",
    "\n",
    "def create_criteo_dataset(file_path, embed_dim=8, test_size=0.2):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "\n",
    "    #缺失值填充\n",
    "    data[dense_features] = data[dense_features].fillna(0)\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "\n",
    "    #归一化\n",
    "    data[dense_features] = MinMaxScaler().fit_transform(data[dense_features])\n",
    "    #LabelEncoding编码\n",
    "    for col in sparse_features:\n",
    "        data[col] = LabelEncoder().fit_transform(data[col]).astype(int)\n",
    "\n",
    "    feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "           [[sparseFeature(feat, data[feat].nunique(), embed_dim) for feat in sparse_features]]\n",
    "\n",
    "    X = data.drop(['label'], axis=1).values\n",
    "    y = data['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return feature_columns, (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c2bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2s 12ms/step - loss: 30.3356 - accuracy: 0.6329\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 11.7153 - accuracy: 0.5291\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 10.5322 - accuracy: 0.5278\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 8.6347 - accuracy: 0.5616\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 7.9350 - accuracy: 0.5553\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 7.4221 - accuracy: 0.5816\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 6.2215 - accuracy: 0.6041\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 5.2569 - accuracy: 0.6373\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 4.9626 - accuracy: 0.6660\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 4.4661 - accuracy: 0.6892\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 3.3003 - accuracy: 0.7473\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 2.5417 - accuracy: 0.7824\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 2.1482 - accuracy: 0.8174\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.8571 - accuracy: 0.8562\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.7588 - accuracy: 0.8543\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.9388 - accuracy: 0.9225\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.0394 - accuracy: 0.9018\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.1759 - accuracy: 0.9099\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.5441 - accuracy: 0.9143\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.9022 - accuracy: 0.9218\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5198 - accuracy: 0.9450\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5031 - accuracy: 0.9550\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.8359 - accuracy: 0.9350\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.8203 - accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.6648 - accuracy: 0.9550\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4518 - accuracy: 0.9681\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4953 - accuracy: 0.9581\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.7991 - accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5805 - accuracy: 0.9568\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4342 - accuracy: 0.9587\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.3523 - accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1884 - accuracy: 0.9894\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4270 - accuracy: 0.9687\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2280 - accuracy: 0.9700\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0655 - accuracy: 0.9969\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1963 - accuracy: 0.9712\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0726 - accuracy: 0.9925\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.7434 - accuracy: 0.9731\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1367 - accuracy: 0.9737\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.4234 - accuracy: 0.9750\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1089 - accuracy: 0.9944\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1478 - accuracy: 0.9750\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0138 - accuracy: 0.9975\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.5887 - accuracy: 0.9719\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.3461 - accuracy: 0.9762\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0691 - accuracy: 0.9919\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.3306 - accuracy: 0.9700\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.7003 - accuracy: 0.9744\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0310 - accuracy: 0.9962\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.3172 - accuracy: 0.9762\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9981\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0227 - accuracy: 0.9981\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.8463 - accuracy: 0.9781\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0094 - accuracy: 0.9975\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4579 - accuracy: 0.9762\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0255 - accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4226 - accuracy: 0.9769\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0158 - accuracy: 0.9981\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0118 - accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.8147 - accuracy: 0.9794\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0306 - accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2081 - accuracy: 0.9775\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0224 - accuracy: 0.9981\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0103 - accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.9781\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0143 - accuracy: 0.9975\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0265 - accuracy: 0.9994\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0096 - accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4692 - accuracy: 0.9775\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0102 - accuracy: 0.9981\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.6844 - accuracy: 0.9787\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0171 - accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9994\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0573 - accuracy: 0.9819\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0228 - accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2258 - accuracy: 0.9781\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0047 - accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0167 - accuracy: 0.9987\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.2134 - accuracy: 0.9787\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0047 - accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0076 - accuracy: 0.9994\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9994\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1185 - accuracy: 0.9794\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0125 - accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0164 - accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.8514 - accuracy: 0.9787\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0194 - accuracy: 0.9969\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4961 - accuracy: 0.9781\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0153 - accuracy: 0.9969\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 12.4749 - accuracy: 0.6025\n",
      "logloss 12.47\n",
      "AUC 0.6\n",
      "Model: \"x_deep_fm_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_104 (Embedding)   multiple                  632       \n",
      "                                                                 \n",
      " embedding_105 (Embedding)   multiple                  2016      \n",
      "                                                                 \n",
      " embedding_106 (Embedding)   multiple                  10344     \n",
      "                                                                 \n",
      " embedding_107 (Embedding)   multiple                  8344      \n",
      "                                                                 \n",
      " embedding_108 (Embedding)   multiple                  240       \n",
      "                                                                 \n",
      " embedding_109 (Embedding)   multiple                  56        \n",
      "                                                                 \n",
      " embedding_110 (Embedding)   multiple                  9312      \n",
      "                                                                 \n",
      " embedding_111 (Embedding)   multiple                  312       \n",
      "                                                                 \n",
      " embedding_112 (Embedding)   multiple                  16        \n",
      "                                                                 \n",
      " embedding_113 (Embedding)   multiple                  7264      \n",
      "                                                                 \n",
      " embedding_114 (Embedding)   multiple                  7408      \n",
      "                                                                 \n",
      " embedding_115 (Embedding)   multiple                  9912      \n",
      "                                                                 \n",
      " embedding_116 (Embedding)   multiple                  6592      \n",
      "                                                                 \n",
      " embedding_117 (Embedding)   multiple                  160       \n",
      "                                                                 \n",
      " embedding_118 (Embedding)   multiple                  6552      \n",
      "                                                                 \n",
      " embedding_119 (Embedding)   multiple                  9272      \n",
      "                                                                 \n",
      " embedding_120 (Embedding)   multiple                  72        \n",
      "                                                                 \n",
      " embedding_121 (Embedding)   multiple                  4272      \n",
      "                                                                 \n",
      " embedding_122 (Embedding)   multiple                  1608      \n",
      "                                                                 \n",
      " embedding_123 (Embedding)   multiple                  32        \n",
      "                                                                 \n",
      " embedding_124 (Embedding)   multiple                  9632      \n",
      "                                                                 \n",
      " embedding_125 (Embedding)   multiple                  56        \n",
      "                                                                 \n",
      " embedding_126 (Embedding)   multiple                  96        \n",
      "                                                                 \n",
      " embedding_127 (Embedding)   multiple                  5832      \n",
      "                                                                 \n",
      " embedding_128 (Embedding)   multiple                  264       \n",
      "                                                                 \n",
      " embedding_129 (Embedding)   multiple                  4432      \n",
      "                                                                 \n",
      " linear_4 (Linear)           multiple                  40        \n",
      "                                                                 \n",
      " dense_layer_4 (Dense_layer)  multiple                 98049     \n",
      "                                                                 \n",
      " cin_4 (CIN)                 multiple                  512512    \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 715,586\n",
      "Trainable params: 715,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses, optimizers\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext tensorboard\n",
    "\n",
    "#create a callback\n",
    "tf_call_back = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file = '../../代码/推荐算法-FM/data/train.txt'\n",
    "    test_size = 0.2\n",
    "    hidden_units = [256, 128, 64]\n",
    "    dropout = 0.3\n",
    "    cin_size = [128, 128]\n",
    "\n",
    "    feature_columns, (X_train, y_train), (X_test, y_test) = create_criteo_dataset(file, test_size=test_size)\n",
    "\n",
    "    model = xDeepFM(feature_columns, cin_size, hidden_units, dropout=dropout)\n",
    "    optimizer = optimizers.SGD(0.01)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_dataset = train_dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # 训练方式一\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_dataset, epochs=100, callbacks=[tf_call_back])\n",
    "    logloss, auc = model.evaluate(X_test, y_test)\n",
    "    print('logloss {}\\nAUC {}'.format(round(logloss,2), round(auc,2)))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "401cd4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 69756), started 0:21:21 ago. (Use '!kill 69756' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-619026fe6f4d6ae2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-619026fe6f4d6ae2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687b7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
